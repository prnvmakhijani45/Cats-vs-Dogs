The Task: I worked on the Cats vs Dogs dataset which I downloaded from Kaggle. I chose this problem to get a hands-on understanding of Convolutional Neural Networks (CNN). Prior to this, I had read a lot about CNN and its importance in the field of Image Recognition but working on this project gave me a deeper understanding into its nuances.
The Approach: My objectives were very simple – 1) Achieving high accuracy and 2) Avoiding overfitting. I emphasized on avoiding overfitting to use this model on other Image Recognition use-cases. The dataset had 25,000 images of cats and dogs distributed equally. To run the model on my local CPU, I decided to train it using 10,000 images. I used the Keras deep learning library for this project and divided my training-testing datasets in 80:20 ratio.
I started by applying the Convolution layer (which is used to extract features) over each image to create Feature Maps. This also helped in removing noise and added non-linearity to the image. The next step is to apply Pooling (the process of maintaining the spatial relationship between pixels, enabling the model to detect objects - irrespective of their location) to these Feature Maps. This helped in reducing the dimensionality of images significantly, while retaining important features. Once we have the pooled Feature Map, we can flatten it into a one-dimensional array which serves as an input layer to an Artificial Neural Network (ANN). I initially trained my ANN using one hidden layer and applied the Stochastic Gradient Descent optimizer to adjust weights during backpropagation.

The Challenges: The biggest challenge was limited computational capacity of my CPU. In the beginning, it took me over 5 hours to train my ANN over 25 epochs. I tried to address this issue by utilizing all the cores of my CPU. This improved the computational time slightly.
The Technical Solution: Initially, I achieved a conservative accuracy of 65% on my test set. To optimize the model further, I made the following changes:
1. Increased the pixel size of my images from 64px to 128px so the model can learn and detect more features.
2. Added a couple of extra Convolution and Pooling layers to prepare well-defined feature sets. I also added two more hidden layers in ANN. The aim was to make my model denser, thereby, improving its prediction capabilities.
3. Changed my optimizer from Stochastic Gradient Descent to Adam’s Optimizer. This was to test the model using a new optimizer.
4. Used Image Augmentation technique which applies random geometric transformations to a random selection of images like rotating/flipping/shifting. Thus, creating many more diverse and multiple batches of images, giving the ANN a lot more data to train on. Since these transformations are random, the model will not find a same picture across the batches.

The Result: The model took 3 hours to run, but its performance on the testing set significantly improved from 65% to 87%. The accuracy on the training set was close to 90%. Hence, I achieved both my targets of accuracy and avoiding overfitting.
Way Forward: I intend to train the model using GPU from Amazon Web Services. I can get a P2 instance for 90 cents an hour. Once I have access to a GPU, I can train my model on the entire dataset rather than just a sample. In addition to adding a couple of extra hidden layers to my ANN, I can also increase the image size from 128px to 256px to get better results. I am confident of achieving over 95% accuracy using these techniques. I can then use this model on different use-cases.
